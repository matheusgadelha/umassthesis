\RequirePackage{fix-cm}
\documentclass[twocolumn]{svjour3}          %
\smartqed  %
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{adjustbox}
\usepackage{mathtools}
\usepackage{xspace}
\usepackage{cite}
\usepackage{xcolor}
\definecolor{citecolor}{HTML}{0071bc}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,citecolor=citecolor,bookmarks=false]{hyperref}

\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\newcommand{\eg}{\textit{e.g.}}
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\set}[1]{\{{#1}\}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\KL}[2]{\mathop{KL}({\textstyle #1}\,\|\,{{\textstyle
      #2}})}
\def\etal{{\em et al.\/}\,}
\def\argmax{\mathop{\rm argmax}}
\def\argmin{\mathop{\rm argmin}}
\def\tr{\mathsf{tr}}
\def\diag{\mathsf{diag}}
\newcommand{\indep}{{\;\bot\!\!\!\!\!\!\bot\;}}
\newcommand\todo[1]{\textcolor{red}{[TODO: #1]}}
\newcommand\new[1]{\textcolor{blue}{#1}}
\newcommand{\prgan}{\textsc{PrGAN}\xspace}
\newcommand{\prgans}{\textsc{PrGANs}\xspace}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\begin{document}

\title{Inferring 3D Shapes from Image Collections using Adversarial Networks%
}


\author{Matheus Gadelha \and
        Aartika Rai  \and
        Subhransu Maji  \and
        Rui Wang
}


\institute{Matheus Gadelha, Aartika Rai, Subhransu Maji, Rui Wang \at
  College of Information and Computer Sciences, University
  of Massachusetts Amherst,   140 Governors Dr, Amherst, MA 01003, USA\\
  \email{\{mgadelha, aartikarai, smaji, ruiwang\}@cs.umass.edu}           %
}

\date{Received: date / Accepted: date}


\maketitle


\begin{abstract}
We investigate the problem of learning a probabilistic distribution over
three-dimensional shapes given two-dimensional views of multiple
objects taken from unknown viewpoints.
Our approach called \emph{projective generative adversarial network}
(\prgan) trains a deep generative model of 3D shapes whose projections
(or renderings) matches the distribution of the provided 2D views.
The addition of a \emph{differentiable projection
module} allows us to infer the underlying 3D shape distribution without
access to any explicit 3D or viewpoint annotation during the learning
phase. 
We show that our approach produces 3D shapes of comparable
quality to GANs trained directly on 3D data. %
Experiments also show that the
disentangled representation of 2D shapes into geometry and viewpoint
leads to a good generative model of 2D shapes.
The key advantage of our model is that it estimates 3D shape, viewpoint, and generates novel
views from an input image in a completely unsupervised manner.
We further investigate how the generative models can be improved
if additional information such as depth, viewpoint or part
segmentations is available at training time.
To this end, we present new differentiable projection operators that can be
used to learn better 3D generative models.
Our experiments show that \prgan can successfully leverage extra visual cues
to create more diverse and accurate shapes.
\end{abstract}

\input{intro.tex}
\input{related.tex}
\input{method.tex}
\input{experiments.tex}
\input{discussion.tex}
\input{conclusion.tex}
\input{ack.tex}

\bibliographystyle{ieee_fullname}
\bibliography{egbib}

\end{document}
