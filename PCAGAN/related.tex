\vspace{-12pt}
\section{Related Work}\label{sec:related}

\noindent \textbf{Generative models for 3D shapes.} Recently, Wu~\etal in~\cite{wu2016learning} proposed a generative model of 3D shapes represented by voxels, using a variant of GAN adapted to 3D convolutions. Two other works are also related. Rezende~\etal~\cite{rezende2016unsupervised} show results for 3D shape completion for simple shapes when views are provided, but require the viewpoints to be known and the generative models are trained on 3D data. Yan~\etal in~\cite{yan2016perspective} learn a mapping from an image to 3D using multiple projections of the 3D shape from known viewpoints (similar to a visual-hull
technique). However, these models operate on a voxel representation of 3D shape, which is difficult to scale up to higher resolution. The network also contains a large number of parameters, which are difficult and take a long time to train. Our method uses spatially partitioned point cloud to represent each shape. It is considerably more lightweight and easy to scale up. In addition, by using a linear shape basis, our network is small hence much easier and faster to train. Through experiments we show that the benefits of this lightweight approach come with no loss of quality compared to previous work. Several recent techniques~\cite{tatarchenko2017octree,Riegler2017CVPR} have explored multi-resolution voxel representations such as \emph{octrees}~\cite{meagher1982geometric} to improve their memory footprint at the expense of additional book keeping. But it remains unclear if 3D-GANs can generate high-resolution sparse outputs.

\vspace{8pt}
\noindent \textbf{Learning a 3D shape bases using point-to-point correspondence.} Another line of work aims to learn a shape basis from data assuming a global alignment of point clouds across models. 
Blanz and Vetter in~\cite{blanz1999morphable} popularized the 3D morphable models for faces which are learned by a PCA analysis of the point clouds across a set of faces with known correspondences. 
The same idea has also been applied to human bodies~\cite{allen2003space}, and other deformable categories~\cite{kar2015category}. 
However, establishing the point-to-point correspondence between 3D shapes is a challenging problem. 
Techniques are based on global rigid or non-rigid pairwise alignment (\eg, \cite{besl1992method,chen1992object,bronstein2010gromov}), learning feature descriptors for matching (\eg, techniques in this survey~\cite{van2011survey}), or fitting a parametric model to each instance (\eg,~\cite{cashman2013shape,prasad2010finding}).
Some techniques improve pairwise correspondence by enforcing cycle-consistency across instances~\cite{huang2013consistent}. 
However, none of these techniques provide consistent global correspondences for shapes with varying and complex structures (\eg, chairs and airplanes). 
Our method uses spatial sorting based on a kd-tree structure. It is a fast and lightweight approximation to the correspondence problem. However, unlike alignment-based approaches, one drawback of the kd-tree sorting is that it's not robust to rotations of the model instances. This is also a drawback of the voxel-based representations.
The ShapeNet dataset~\cite{chang2015shapenet} used in our experiments already contains objects that are consistently oriented, but otherwise one can apply automatic techniques (\eg,~\cite{Su_2015_ICCV}) for viewpoint estimation to achieve this.

\vspace{8pt}
\noindent \textbf{Representing shapes as sets.} Another direction is to use loss functions over \emph{sets} such as Chamfer, Hausdroff, or Earth Mover's Distance (EMD) to estimate similarity between models. The recent work of Fan~\etal~\cite{fan2016point} explores this direction and trains a neural network to generate points from a single image by minimizing the EMD between the generated points and the model points. To apply this approach for shape generation one requires the evaluation of the loss of a generated shape with respect to a distribution of target shapes. While this can be approximated by computing statistics of EMD distance of the generated shape to all shapes in the training data, this is highly inefficient since EMD computation alone scales cubically with the number of points. 
Thus training neural architectures to generate and evaluate loss functions over sets efficiently remains an open problem. 
The approximate ordering induced by the kd-tree allows efficient matrix operations on the \emph{ordered} vector of point coordinates for training shape generators and discriminators.
